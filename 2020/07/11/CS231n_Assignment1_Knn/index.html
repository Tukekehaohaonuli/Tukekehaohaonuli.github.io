<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Tukekenulia♥</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="此篇仅记录自己学习CS231n的习题成果所用">
<meta property="og:type" content="article">
<meta property="og:title" content="Tukekenulia♥">
<meta property="og:url" content="http://yoursite.com/2020/07/11/CS231n_Assignment1_Knn/index.html">
<meta property="og:site_name" content="Tukekenulia♥">
<meta property="og:description" content="此篇仅记录自己学习CS231n的习题成果所用">
<meta property="og:locale">
<meta property="article:published_time" content="2020-07-11T08:46:50.000Z">
<meta property="article:modified_time" content="2020-07-11T08:46:50.000Z">
<meta property="article:author" content="Tukeke">
<meta name="twitter:card" content="summary">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link type="text/css" href="//netdna.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.css" rel="stylesheet">
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/css/scrollUp/image.css">

  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
<meta name="generator" content="Hexo 6.3.0"></head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <div class="logo">
        <img src="/logo.png" alt="Profile Picture">
      </div>
      <div id="title">Tukekenulia♥</div>
      
        <div id="subtitle">Stay focus,stay humble,stay curiosity.</div>
      
       <ul class="my-socials">
  
  <li>
  	<a href="https://github.com/Tukekehaohaonuli" class="github" target="_blank">
  		<i class="fa fa-github"></i>
  	</a>
  </li>
  
  <li>
  	<a href="YOUR WEIBO HOME PAGE URL" class="weibo" target="_blank">
  		<i class="fa fa-weibo"></i>
  	</a>
  </li>
  
 
</ul>
    </div>
  </div>
  <div id="header-inner" class="">
    <nav id="main-nav">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <!--
        
          
            <a class="main-nav-link" href="/">首页</a>
          
            <a class="main-nav-link" href="/categories/life">生活</a>
          
            <a class="main-nav-link" href="/archives">归档</a>
          
        
      -->
    </nav>
    <nav id="title-nav" style="display:none">
      <a href="/">Tukekenulia♥</a>
      <img src="/logo.png" alt="Profile Picture">
      <!--
      <span id="title-nav-socials">
        
       
     </span>
      -->
    </nav>
    <nav id="sub-nav">
      
      <a id="nav-search-btn" class="nav-icon" title="Search"></a>
    </nav>
    <div id="search-form-wrap">
      <form action="http://www.baidu.com/baidu" method="get" accept-charset="utf-8" class="search-form">
        <input type="search" name="word" maxlength="20" class="search-form-input" placeholder="Search">
        <input type="submit" value="" class="search-form-submit">
        <input name=tn type=hidden value="bds">
        <input name=cl type=hidden value="3">
        <input name=ct type=hidden value="2097152">
        <input type="hidden" name="si" value="yoursite.com">
      </form>
    </div>
  </div>
  <div class="site-nav" style="display: none;">
    <ul>
      
      
        <li><a href="/">首页</a></li>
      
        <li><a href="/categories/life">生活</a></li>
      
        <li><a href="/archives">归档</a></li>
      
      
    </ul>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-CS231n_Assignment1_Knn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/07/11/CS231n_Assignment1_Knn/" class="article-date">
  <time datetime="2020-07-11T08:46:50.000Z" itemprop="datePublished">2020-07-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>此篇仅记录自己学习CS231n的习题成果所用</p>
<span id="more"></span>

<p>关于2017CS231N的课时分配，assignment相关链接：</p>
<p><a target="_blank" rel="noopener" href="http://cs231n.stanford.edu/2017/syllabus?tdsourcetag=s_pctim_aiomsg">http://cs231n.stanford.edu/2017/syllabus?tdsourcetag=s_pctim_aiomsg</a></p>
<p>视频观看地址在B站:</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1LJ411g724?p=1">https://www.bilibili.com/video/BV1LJ411g724?p=1</a></p>
<h1 id="KNN-py"><a href="#KNN-py" class="headerlink" title="KNN.py"></a>KNN.py</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br></pre></td><td class="code"><pre><span class="line">//knn.py</span><br><span class="line"></span><br><span class="line">//设置显示图像的初始值</span><br><span class="line">import random</span><br><span class="line">import numpy as np</span><br><span class="line">from cs231n.data_utils import load_CIFAR10</span><br><span class="line">import matplotlib.pyplot as plt   </span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[&#x27;figure.figsize&#x27;] = (10.0, 8.0) # set default size of plots  //设置图形的界面的大小</span><br><span class="line">plt.rcParams[&#x27;image.interpolation&#x27;] = &#x27;nearest&#x27;  //选择一种图像显示的方式</span><br><span class="line">plt.rcParams[&#x27;image.cmap&#x27;] = &#x27;gray&#x27;    //色彩图</span><br><span class="line"></span><br><span class="line">################################################################</span><br><span class="line"></span><br><span class="line">cifar10_dir = &#x27;cs231n/datasets/cifar-10-batches-py&#x27;</span><br><span class="line"></span><br><span class="line"># Cleaning up variables to prevent loading data multiple times (which may cause memory issue)   //清理缓存</span><br><span class="line">try:</span><br><span class="line">   del X_train, y_train</span><br><span class="line">   del X_test, y_test</span><br><span class="line">   print(&#x27;Clear previously loaded data.&#x27;)</span><br><span class="line">except:</span><br><span class="line">   pass</span><br><span class="line"></span><br><span class="line">X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir) //载入数据</span><br><span class="line">   x_train //共5份训练集，一份包含10000张32*32的RGB图片 </span><br><span class="line">   y_train //对应50000个训练集的标签 如 &#x27;plane&#x27;</span><br><span class="line">   X_test //一份测试集 对应10000张32*32的三通道RGB图片</span><br><span class="line">   y_test //对应测试集的 10000个标签</span><br><span class="line"></span><br><span class="line">print(&#x27;Training data shape: &#x27;, X_train.shape)</span><br><span class="line">print(&#x27;Training labels shape: &#x27;, y_train.shape)</span><br><span class="line">print(&#x27;Test data shape: &#x27;, X_test.shape)</span><br><span class="line">print(&#x27;Testlabels shape: &#x27;, y_test.shape)</span><br><span class="line"></span><br><span class="line">#####################################################################</span><br><span class="line"></span><br><span class="line">//将训练集中的数据每个标签选择7个样本输出显示</span><br><span class="line"></span><br><span class="line">classes = [&#x27;plane&#x27;, &#x27;car&#x27;, &#x27;bird&#x27;, &#x27;cat&#x27;, &#x27;deer&#x27;, &#x27;dog&#x27;, &#x27;frog&#x27;, &#x27;horse&#x27;, &#x27;ship&#x27;, &#x27;truck&#x27;]     //类别</span><br><span class="line">num_classes = len(classes)   //类别的数量</span><br><span class="line">samples_per_class = 7     //每种类型选择7个样本</span><br><span class="line">for y, cls in enumerate(classes):   //enumerate是将classes数据中的下标以及关键字赋值给y、cls</span><br><span class="line">                                    比如y=0，cls=‘plane’</span><br><span class="line">    idxs = np.flatnonzero(y_train == y)   //取出与Y标签相同的训练集的下标,以矩阵形式保存</span><br><span class="line">    idxs = np.random.choice(idxs, samples_per_class, replace=False) //从矩阵中随机选择idxs中的7个样本</span><br><span class="line">   //replace=True 则表示可以取相同，False则表示不能</span><br><span class="line">    for i, idx in enumerate(idxs):    i表示下标，idx表示取出的标签在训练集中的位置</span><br><span class="line">        plt_idx = i * num_classes + y + 1   </span><br><span class="line">        plt.subplot(samples_per_class, num_classes, plt_idx)// 7行11列，plt_idx表示显示的figure中的位置</span><br><span class="line">        plt.imshow(X_train[idx].astype(&#x27;uint8&#x27;)) //显示训练集中的第idx张图</span><br><span class="line">        plt.axis(&#x27;off&#x27;)</span><br><span class="line">        if i == 0:</span><br><span class="line">            plt.title(cls)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">#####################################################################</span><br><span class="line">//减少工作量，将50000张训练集缩小十倍</span><br><span class="line"></span><br><span class="line">num_training = 5000          //选择5000张样本 减少工作量</span><br><span class="line">mask = list(range(num_training))  //range(5000)  选择前5K张数据保存在X_train中</span><br><span class="line">X_train = X_train[mask]  </span><br><span class="line">y_train = y_train[mask] //缩小训练集和标签的数量</span><br><span class="line"></span><br><span class="line">num_test = 500</span><br><span class="line">mask = list(range(num_test))</span><br><span class="line">X_test = X_test[mask]</span><br><span class="line">y_test = y_test[mask]     //测试集同理</span><br><span class="line"></span><br><span class="line"># Reshape the image data into rows</span><br><span class="line">X_train = np.reshape(X_train, (X_train.shape[0], -1))  //重建训练集和测试集</span><br><span class="line">X_test = np.reshape(X_test, (X_test.shape[0], -1))</span><br><span class="line">print(X_train.shape, X_test.shape)      </span><br><span class="line">(5000, 3072) (500, 3072)      //5000代表5000张图，3072=32*32*3 表示一章图的像点乘上三通道</span><br><span class="line"></span><br><span class="line">#####################################################################</span><br><span class="line"></span><br><span class="line">from cs231n.classifiers import KNearestNeighbor</span><br><span class="line"></span><br><span class="line">classifier = KNearestNeighbor() </span><br><span class="line">classifier.train(X_train, y_train)</span><br><span class="line"></span><br><span class="line">#####################################################################</span><br><span class="line"></span><br><span class="line">dists = classifier.compute_distances_two_loops(X_test) //传入测试集的数据</span><br><span class="line">print(dists.shape)   //距离矩阵为500*5000</span><br><span class="line"></span><br><span class="line">#####################################################################</span><br><span class="line"></span><br><span class="line">plt.imshow(dists, interpolation=&#x27;none&#x27;)    //interpolation为显示图像的方式</span><br><span class="line">  //具体可见 https://blog.csdn.net/liangjiubujiu/article/details/80420555</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">#####################################################################</span><br><span class="line"></span><br><span class="line">//计算输出两层循环的准确率</span><br><span class="line"></span><br><span class="line">y_test_pred = classifier.predict_labels(dists, k=1)    //传入距离矩阵disks和k=1</span><br><span class="line">//得到每个测试点的标签矩阵</span><br><span class="line">num_correct = np.sum(y_test_pred == y_test)  //测试结果和预测结果相同的数量</span><br><span class="line">accuracy = float(num_correct) / num_test</span><br><span class="line">print(&#x27;Got %d / %d correct =&gt; accuracy: %f&#x27; % (num_correct, num_test, accuracy))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#####################################################################</span><br><span class="line">//计算k=5时的预测值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y_test_pred = classifier.predict_labels(dists, k=5)</span><br><span class="line">num_correct = np.sum(y_test_pred == y_test)</span><br><span class="line">accuracy = float(num_correct) / num_test</span><br><span class="line">print(&#x27;Got %d / %d correct =&gt; accuracy: %f&#x27; % (num_correct, num_test, accuracy))</span><br><span class="line"></span><br><span class="line">#####################################################################</span><br><span class="line">dists_one = classifier.compute_distances_one_loop(X_test)  </span><br><span class="line">//使用单层循环所得到的预测结果和双层循环的结果相同</span><br><span class="line"></span><br><span class="line">difference = np.linalg.norm(dists - dists_one, ord=&#x27;fro&#x27;)</span><br><span class="line">print(&#x27;One loop difference was: %f&#x27; % (difference, ))</span><br><span class="line">if difference &lt; 0.001:</span><br><span class="line">    print(&#x27;Good! The distance matrices are the same&#x27;)</span><br><span class="line">else:</span><br><span class="line">    print(&#x27;Uh-oh! The distance matrices are different&#x27;)</span><br><span class="line">    </span><br><span class="line">#####################################################################</span><br><span class="line">//不用循环计算距离矩阵的结果与两层循环结果准确率的对比</span><br><span class="line"></span><br><span class="line">dists_two = classifier.compute_distances_no_loops(X_test)</span><br><span class="line"></span><br><span class="line"># check that the distance matrix agrees with the one we computed before:</span><br><span class="line">difference = np.linalg.norm(dists - dists_two, ord=&#x27;fro&#x27;)</span><br><span class="line">//linalg.norm 求范数 ~~~~</span><br><span class="line">print(&#x27;No loop difference was: %f&#x27; % (difference, ))</span><br><span class="line">if difference &lt; 0.001:</span><br><span class="line">    print(&#x27;Good! The distance matrices are the same&#x27;)</span><br><span class="line">else:</span><br><span class="line">    print(&#x27;Uh-oh! The distance matrices are different&#x27;)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">#####################################################################</span><br><span class="line">def time_function(f, *args):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Call a function f with args and return the time (in seconds) that it took to execute.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    import time</span><br><span class="line">    tic = time.time()     //记录运行函数之前的时间</span><br><span class="line">    f(*args)              //运行传入的函数，*args为传入的测试集</span><br><span class="line">    toc = time.time()     //记录运行函数之后的时间</span><br><span class="line">    return toc - tic      //返回执行该函数所需时间</span><br><span class="line"></span><br><span class="line">two_loop_time = time_function(classifier.compute_distances_two_loops, X_test)</span><br><span class="line">print(&#x27;Two loop version took %f seconds&#x27; % two_loop_time)</span><br><span class="line"></span><br><span class="line">one_loop_time = time_function(classifier.compute_distances_one_loop, X_test)</span><br><span class="line">print(&#x27;One loop version took %f seconds&#x27; % one_loop_time)</span><br><span class="line"></span><br><span class="line">no_loop_time = time_function(classifier.compute_distances_no_loops, X_test)</span><br><span class="line">print(&#x27;No loop version took %f seconds&#x27; % no_loop_time)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#####################################################################</span><br><span class="line">//交叉验证</span><br><span class="line"></span><br><span class="line">num_folds = 5    //分成5份数据，交叉验证，其中一份为测试集</span><br><span class="line">k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]  //选择不同K的值时预测的准确率</span><br><span class="line"></span><br><span class="line">X_train_folds =[]    //建立分成5份之后的测试集数组</span><br><span class="line">y_train_folds =[]</span><br><span class="line"></span><br><span class="line">y_train=y_train.reshape(-1,1)      //可省略行 本身就是</span><br><span class="line">X_train_folds = np.array_split(X_train,num_folds)    //将X_train中的数据分成num_folds份</span><br><span class="line">y_train_folds = np.array_split(y_train,num_folds)</span><br><span class="line"></span><br><span class="line">pass</span><br><span class="line"></span><br><span class="line">k_to_accuracies = &#123;&#125; </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for k in k_choices:     //初始化字典KEY的值，value的值设为空</span><br><span class="line">    k_to_accuracies.setdefault(k,[])</span><br><span class="line"></span><br><span class="line">for i in range(num_folds):     //交叉验证num_folds次</span><br><span class="line">    classifier=KNearestNeighbor()</span><br><span class="line">    x_val_train=np.vstack(X_train_folds[0:i]+X_train_folds[i+1:]) </span><br><span class="line">    y_val_train=np.vstack(y_train_folds[0:i]+y_train_folds[i+1:])</span><br><span class="line">    y_val_train=y_val_train[:,0]   //除去第i个的测试集，保留下剩余的为训练集</span><br><span class="line">    classifier.train(x_val_train,y_val_train)   //将训练集图像和标签传入</span><br><span class="line">    for k in k_choices:</span><br><span class="line">        y_val_pred=classifier.predict(X_train_folds[i],k=k)  //预测测试集的标签，获得标签数组</span><br><span class="line">        num_correct=np.sum(y_val_pred==y_train_folds[i][:,0])  </span><br><span class="line">        accuracy=float(num_correct)/len(y_val_pred)  //正确的百分比</span><br><span class="line">        k_to_accuracies[k]=k_to_accuracies[k]+[accuracy] //将k对应的准确率导入到字典中，其中准确率为单独的数组</span><br><span class="line">        </span><br><span class="line">pass</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Print out the computed accuracies</span><br><span class="line">for k in sorted(k_to_accuracies):</span><br><span class="line">    for accuracy in k_to_accuracies[k]:</span><br><span class="line">        print(&#x27;k = %d, accuracy = %f&#x27; % (k, accuracy))</span><br><span class="line">        //打印预测数组值</span><br><span class="line">        </span><br><span class="line">################################################################################</span><br><span class="line">//显示输出所得k对应准确率的图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for k in k_choices:</span><br><span class="line">    accuracies = k_to_accuracies[k]</span><br><span class="line">    plt.scatter([k] * len(accuracies), accuracies)  //将K对应的准确值以图像的形式呈现</span><br><span class="line"></span><br><span class="line"># plot the trend line with error bars that correspond to standard deviation</span><br><span class="line">//用与标准偏差对应的误差条绘制趋势线 </span><br><span class="line"></span><br><span class="line">accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])</span><br><span class="line">accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])</span><br><span class="line">plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)</span><br><span class="line">plt.title(&#x27;Cross-validation on k&#x27;)</span><br><span class="line">plt.xlabel(&#x27;k&#x27;)</span><br><span class="line">plt.ylabel(&#x27;Cross-validation accuracy&#x27;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">################################################################################</span><br><span class="line">//既然已经知道了K值为何值是的准确率最高，那么就选择最佳的K值输出测试集的准确率，结果不应低于28%</span><br><span class="line"></span><br><span class="line">best_k = 10</span><br><span class="line"></span><br><span class="line">classifier = KNearestNeighbor()</span><br><span class="line"></span><br><span class="line">y_train=y_train[:,0]  //在训练中，y_train变成了2维数组，因此会造成object too deep for desired array的报错，只需要将它重新设置为一维数组即可</span><br><span class="line">classifier.train(X_train, y_train)</span><br><span class="line">y_test_pred = classifier.predict(X_test, k=best_k)</span><br><span class="line"></span><br><span class="line"># Compute and display the accuracy</span><br><span class="line">num_correct = np.sum(y_test_pred == y_test)</span><br><span class="line">accuracy = float(num_correct) / num_test</span><br><span class="line">print(&#x27;Got %d / %d correct =&gt; accuracy: %f&#x27; % (num_correct, num_test, accuracy))</span><br><span class="line"></span><br><span class="line">//</span><br></pre></td></tr></table></figure>

<h1 id="K-nearest-neighbor-py"><a href="#K-nearest-neighbor-py" class="headerlink" title="K_nearest_neighbor.py"></a>K_nearest_neighbor.py</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">//k_nearest_neighbor.py</span><br><span class="line"></span><br><span class="line">from builtins import range</span><br><span class="line">from builtins import object</span><br><span class="line">import numpy as np</span><br><span class="line">from past.builtins import xrange</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class KNearestNeighbor(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">    def train(self, X, y):  //赋初值</span><br><span class="line">        </span><br><span class="line">        self.X_train = X</span><br><span class="line">        self.y_train = y</span><br><span class="line"></span><br><span class="line">    def predict(self, X, k=1, num_loops=0): //不同距离矩阵算法选择</span><br><span class="line">       </span><br><span class="line">       </span><br><span class="line">        if num_loops == 0:</span><br><span class="line">            dists = self.compute_distances_no_loops(X)</span><br><span class="line">        elif num_loops == 1:</span><br><span class="line">            dists = self.compute_distances_one_loop(X)</span><br><span class="line">        elif num_loops == 2:</span><br><span class="line">            dists = self.compute_distances_two_loops(X)</span><br><span class="line">        else:</span><br><span class="line">            raise ValueError(&#x27;Invalid value %d for num_loops&#x27; % num_loops)</span><br><span class="line"></span><br><span class="line">        return self.predict_labels(dists, k=k)</span><br><span class="line"></span><br><span class="line">   def compute_distances_two_loops(self, X):  //self是自带的参数值</span><br><span class="line">   </span><br><span class="line">         //计算X中每个测试点与每个训练点之间的距离 X_train=X_train,y_train=y_train</span><br><span class="line">       </span><br><span class="line">        num_test = X.shape[0]  //X=X_test //测试集数据 self中是训练集数据</span><br><span class="line">                               //shape[0] 输出测试集的行数 </span><br><span class="line">        num_train = self.X_train.shape[0]</span><br><span class="line">        dists = np.zeros((num_test, num_train))  //设置行为测试集行数，列为训练集行数的0矩阵</span><br><span class="line">        for i in range(num_test):</span><br><span class="line">            for j in range(num_train):</span><br><span class="line">                dists[i,j]=np.sqrt(np.sum((X[i,:]-self.X_train[j,:])**2))             </span><br><span class="line"></span><br><span class="line">                pass</span><br><span class="line">                </span><br><span class="line">        return dists</span><br><span class="line">   </span><br><span class="line">   def compute_distances_one_loop(self, X):</span><br><span class="line">      </span><br><span class="line">        num_test = X.shape[0]</span><br><span class="line">        num_train = self.X_train.shape[0]</span><br><span class="line">        dists = np.zeros((num_test, num_train))</span><br><span class="line">        for i in range(num_test):</span><br><span class="line">           </span><br><span class="line">            dists[i,:]=np.sqrt(np.sum((self.X_train - X[i])**2),axis=1)</span><br><span class="line"></span><br><span class="line">            pass</span><br><span class="line"></span><br><span class="line">        return dists</span><br><span class="line">      </span><br><span class="line">      </span><br><span class="line">    def compute_distances_no_loops(self, X):  //无循环计算距离</span><br><span class="line"></span><br><span class="line">        num_test = X.shape[0]</span><br><span class="line">        num_train = self.X_train.shape[0]</span><br><span class="line">        dists = np.zeros((num_test, num_train))</span><br><span class="line">        </span><br><span class="line">        test_sum=np.sum(np.square(X),axis=1)</span><br><span class="line">        train_sum=np.sum(np.square(self.X_train),axis=1)</span><br><span class="line">        #print(train_sum.shape,test_sum.shape)</span><br><span class="line">        inner_product=np.dot(X,self.X_train.T)  </span><br><span class="line">        dists=np.sqrt(-2*inner_product+test_sum.reshape(-1,1)+train_sum.T) </span><br><span class="line">        //我认为这里是train_sum.T而不是train_sum</span><br><span class="line">        #print(test_sum.shape)</span><br><span class="line">		//（x1-x2)**2 == x1**2+x2**2-2*x1*x2</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">        return dists</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">def predict_labels(self, dists, k=1):  //找到第i个测试点最近的K个点</span><br><span class="line">        num_test = dists.shape[0]      //距离矩阵的行数</span><br><span class="line">        y_pred = np.zeros(num_test)    //建立一个0矩阵，行数和距离矩阵相同</span><br><span class="line">        for i in range(num_test):</span><br><span class="line">           </span><br><span class="line">            closest_y = self.y_train[np.argsort(dists[i])[0:k]]  //存有K个测试点的标签</span><br><span class="line">          </span><br><span class="line"></span><br><span class="line">            pass</span><br><span class="line"></span><br><span class="line">           </span><br><span class="line">            y_pred[i]=np.argmax(np.bincount(closest_y))</span><br><span class="line"></span><br><span class="line">            pass</span><br><span class="line"></span><br><span class="line">        return y_pred</span><br></pre></td></tr></table></figure>














      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://yoursite.com/2020/07/11/CS231n_Assignment1_Knn/" data-id="clkwhj3tx00066s7sgsmv8or0" class="article-share-link">Share</a>
      

      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/07/20/python%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="/2020/07/11/CS231n_Assignment1_Softmax/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>

</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 Tukeke<br>
      Theme <a href="https://github.com/Tukekehaohaonuli/" target="_blank">Oishi</a>, Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <!--
      <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/categories/life" class="mobile-nav-link">生活</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
</nav>
    -->
    

<!-- 百度分享 start -->

<!-- 百度分享 end -->

<script src="//cdn.bootcss.com/jquery/1.11.1/jquery.min.js"></script>




<script src="/js/jquery.scrollUp.min.js"></script>


<script src="/js/jquery.transform.js"></script>


<script src="/js/menu.js"></script>



<script src="/js/script.js"></script>


<script src="/js/scrollUp.js"></script>


  </div>
</body>
</html>
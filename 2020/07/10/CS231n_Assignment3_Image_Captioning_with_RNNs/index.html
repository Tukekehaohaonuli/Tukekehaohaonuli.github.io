<!DOCTYPE html>
<html  lang="english" >
    <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, minimum-scale=1, initial-scale=1, maximum-scale=5, viewport-fit=cover">
    <title>Tukekenulia</title>
    <meta name="description" content="前言:在开始之前，需要下载Stanford University训练好的数据集，因为是Win10系统，所以需要把命令行中的链接一个个抠出来挂上VPN下载。下载完成Coco Datasets数据集后才可开始assignment3的作业">
<meta property="og:type" content="article">
<meta property="og:title" content="Tukekenulia">
<meta property="og:url" content="http://yoursite.com/2020/07/10/CS231n_Assignment3_Image_Captioning_with_RNNs/index.html">
<meta property="og:site_name" content="Tukekenulia">
<meta property="og:description" content="前言:在开始之前，需要下载Stanford University训练好的数据集，因为是Win10系统，所以需要把命令行中的链接一个个抠出来挂上VPN下载。下载完成Coco Datasets数据集后才可开始assignment3的作业">
<meta property="og:locale">
<meta property="og:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/3.png">
<meta property="og:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/4.png">
<meta property="og:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/5.png">
<meta property="og:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/6.png">
<meta property="og:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/7.png">
<meta property="og:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/8.png">
<meta property="og:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/9.png">
<meta property="og:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/10.png">
<meta property="og:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/11.png">
<meta property="og:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/12.png">
<meta property="og:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/13.png">
<meta property="og:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/14.png">
<meta property="og:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/2.png">
<meta property="og:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/1.png">
<meta property="article:published_time" content="2020-07-10T03:02:38.000Z">
<meta property="article:modified_time" content="2020-07-10T03:02:38.000Z">
<meta property="article:author" content="Tukeke">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/images/CS231n_Assignment3_Image_Captioning_with_RNNs/3.png">

    
    <link rel="icon" href="/images/icon.png" type="image/x-icon">

    
<link rel="stylesheet" href="/css/common.min.css">



    
    
    
    
        <link href="//cdn.jsdelivr.net/npm/lightgallery.js@1.1.3/dist/css/lightgallery.min.css" rel="stylesheet">
    
    
    
<link rel="stylesheet" href="/css/iconfont.min.css">

    
<meta name="generator" content="Hexo 6.3.0"></head>

    <body>
        <header class="header header-fixture">
    <div class="profile-search-wrap flex sm:block">
        
        
        <div class="profile sm:text-center md:px-1 lg:px-3 sm:pb-4 sm:pt-6">
            <a id="avatar" role="link" href="https://github.com/fengkx" class="inline-block lg:w-16 lg:h-16 w-8 h-8 m-2" target="_blank" rel="noopener" rel="noreferrer" >
                <img src="https://www.gravatar.com/avatar/0bc83cb571cd1c50ba6f3e8a78ef1346?s=128" class="rounded-full" alt="avatar">
            </a>
            <h2 id="name" class="hidden lg:block">fengkx</h2>
            <h3 id="title" class="hidden lg:block">Student &amp; Coder</h3>
            
            <small id="location" class="hidden lg:block">
                <i class="iconfont icon-map-icon"></i>
                Wenzhou11, China
            </small>
            
        </div>
        
        
<div class="search flex-1 flex lg:inline-block sm:hidden lg:px-4 lg:mt-2 lg:mb-4 lg:w-full">
    <form id="search-form" class="my-auto flex-1 lg:border lg:border-solid lg:border-gray-200">
        <div class="input-group table bg-gray-100 lg:bg-white w-full">
            <input id="search-input" type="text" placeholder="Search" class="inline-block w-full bg-gray-100 lg:bg-white p-1">
            <span class="table-cell">
                <button name="search tigger button" disabled>
                    <i class="iconfont icon-search m-2"></i>
                </button>
            </span>
        </div>
    </form>
        
<div id="content-json" data-placeholder="Search" class="invisible hidden">/content.json</div>
<script id="search-teamplate" type="text/html" data-path="/content.json">
    <div>
        <div class="search-header bg-gray-400">
            <input id="actual-search-input" model="keyword" ref="input" class="inline-block w-full h-10 px-2 py-1" placeholder="Search" type="text">
        </div>
        <div class="search-result bg-gray-200">
            {{#each searchPosts}}
            <a href="/{{ path }}" class="result-item block px-2 pb-3 mb-1 pt-1 hover:bg-indigo-100">
                <i class="iconfont icon-file"></i>
                <h1 class="result-title inline font-medium text-lg">{{ title }}</h1>
                <p class="result-content text-gray-600 text-sm">{{{ text }}}</p>
            </a>
            {{/each}}
        </div>
    </div>
</script>

</div>


        <button name="menu toogle button" id="menu-toggle-btn" class="block sm:hidden p-3" role="button" aria-expanded="false">
            <i class="iconfont icon-hamburger"></i>
        </button>
    </div>
    <nav id="menu-nav" class="hidden sm:flex flex-col">
        
        
            <div class="menu-item menu-home" role="menuitem">
                <a href="/.">
                    <i class="iconfont icon-home" aria-hidden="true"></i>
                    <span class="menu-title">Home</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-archives" role="menuitem">
                <a href="/archives">
                    <i class="iconfont icon-archive" aria-hidden="true"></i>
                    <span class="menu-title">Archives</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-categories" role="menuitem">
                <a href="/categories">
                    <i class="iconfont icon-folder" aria-hidden="true"></i>
                    <span class="menu-title">Categories</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-tags" role="menuitem">
                <a href="/tags">
                    <i class="iconfont icon-tag" aria-hidden="true"></i>
                    <span class="menu-title">Tags</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-repository" role="menuitem">
                <a href="/repository">
                    <i class="iconfont icon-project" aria-hidden="true"></i>
                    <span class="menu-title">Repository</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-links" role="menuitem">
                <a href="/links">
                    <i class="iconfont icon-friend" aria-hidden="true"></i>
                    <span class="menu-title">Links</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-about" role="menuitem">
                <a href="/about">
                    <i class="iconfont icon-cup" aria-hidden="true"></i>
                    <span class="menu-title">About</span>
                </a>
            </div>
        
        
<div class="social-links flex sm:flex-col lg:hidden mt-5">
    
        <span class="social-item text-center">
            <a target="_blank" rel="noopener" href="https://github.com/fengkx">
                <i class="iconfont social-icon icon-github"></i>
                <span class="menu-title hidden lg:inline">menu.github</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a target="_blank" rel="noopener" href="https://t.me/fengkx">
                <i class="iconfont social-icon icon-telegram"></i>
                <span class="menu-title hidden lg:inline">menu.telegram</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a target="_blank" rel="noopener" href="https://twitter.com/example">
                <i class="iconfont social-icon icon-twitter"></i>
                <span class="menu-title hidden lg:inline">menu.twitter</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a href="/atom.xml">
                <i class="iconfont social-icon icon-rss"></i>
                <span class="menu-title hidden lg:inline">menu.rss</span>
            </a>
        </span>
    
</div>


    </nav>
</header>

        <section class="main-section">
            
    <main class="flex-1 px-4 py-14 md:px-5 lg:px-8 lg:py-4 relative min-h-screen">
    

    <article class="content article article-archives article-type-list" itemscope="">
        <header class="article-header">
            


            <p class="article-meta mb-3 text-xs">
                <span class="article-date">
    <i class="iconfont icon-calendar-check"></i>
	<a href="/2020/07/10/CS231n_Assignment3_Image_Captioning_with_RNNs/" class="article-date">
	  <time datetime="2020-07-10T03:02:38.000Z" itemprop="datePublished">Jul 10</time>
	</a>
</span>

                

                

                <span class="_partial/post-comment"><i class="icon icon-comment"></i>
                    <a href="/2020/07/10/CS231n_Assignment3_Image_Captioning_with_RNNs/#comments" class="article-comment-link">
                        Comments
                    </a>
                </span>
                

            </p>
        </header>
        <div class="marked-body article-body">
            <p>前言:在开始之前，需要下载<em>Stanford</em> University训练好的数据集，因为是Win10系统，所以需要把命令行中的链接一个个抠出来挂上VPN下载。下载完成Coco Datasets数据集后才可开始assignment3的作业</p>
<span id="more"></span>

<h1 id="Image-Captioning-with-RNNs"><a href="#Image-Captioning-with-RNNs" class="headerlink" title="Image Captioning with RNNs"></a>Image Captioning with RNNs</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># As usual, a bit of setup</span><br><span class="line">from __future__ import print_function</span><br><span class="line">import time, os, json</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array</span><br><span class="line">from cs231n.rnn_layers import *</span><br><span class="line">from cs231n.captioning_solver import CaptioningSolver</span><br><span class="line">from cs231n.classifiers.rnn import CaptioningRNN</span><br><span class="line">from cs231n.coco_utils import load_coco_data, sample_coco_minibatch, decode_captions</span><br><span class="line">from cs231n.image_utils import image_from_url</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[&#x27;figure.figsize&#x27;] = (10.0, 8.0) # set default size of plots</span><br><span class="line">plt.rcParams[&#x27;image.interpolation&#x27;] = &#x27;nearest&#x27;</span><br><span class="line">plt.rcParams[&#x27;image.cmap&#x27;] = &#x27;gray&#x27;</span><br><span class="line"></span><br><span class="line"># for auto-reloading external modules</span><br><span class="line"># see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython</span><br><span class="line">%load_ext autoreload</span><br><span class="line">%autoreload 2</span><br><span class="line"></span><br><span class="line">def rel_error(x, y):</span><br><span class="line">    &quot;&quot;&quot; returns relative error &quot;&quot;&quot;</span><br><span class="line">    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))</span><br></pre></td></tr></table></figure>

<h3 id="Microsoft-COCO"><a href="#Microsoft-COCO" class="headerlink" title="Microsoft COCO"></a>Microsoft COCO</h3><p>导入Coco数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Load COCO data from disk; this returns a dictionary</span><br><span class="line"># We&#x27;ll work with dimensionality-reduced features for this notebook, but feel</span><br><span class="line"># free to experiment with the original features by changing the flag below.</span><br><span class="line">data = load_coco_data(pca_features=True)</span><br><span class="line"></span><br><span class="line"># Print out all the keys and values from the data dictionary</span><br><span class="line">for k, v in data.items():</span><br><span class="line">    if type(v) == np.ndarray:</span><br><span class="line">        print(k, type(v), v.shape, v.dtype)</span><br><span class="line">    else:</span><br><span class="line">        print(k, type(v), len(v))</span><br></pre></td></tr></table></figure>



<p>查看一部分的数据集这段代码加载不了~~~~可能是因为是外网的原因，没有VPN连接不了。在此跳过</p>
<p><img src="/images/CS231n_Assignment3_Image_Captioning_with_RNNs/3.png" alt="3"></p>
<h3 id="Recurrent-Neural-Networks-正文段开始-RNN"><a href="#Recurrent-Neural-Networks-正文段开始-RNN" class="headerlink" title="Recurrent Neural Networks 正文段开始 RNN"></a>Recurrent Neural Networks 正文段开始 RNN</h3><h3 id="Vanilla-RNN-step-forward"><a href="#Vanilla-RNN-step-forward" class="headerlink" title="Vanilla RNN: step forward"></a>Vanilla RNN: step forward</h3><p>这里稍微做一下解释，为什么成为Vanilla RNN， 也可以翻译为朴素的VanillaRNN算法，因为在这种循环卷积神经网络训练过程中，由于递归结构的简单，因此会造成梯度消失(&lt;1)或者说梯度爆炸的问题(&gt;1)因此称这种RNN为朴素的RNN算法，在后面的LSTM会对递归结构进行改进。</p>
<p>在rnn_layers.py完成单步runn_step_forward函数，并在这里检验误差</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">N, D, H = 3, 10, 4</span><br><span class="line"></span><br><span class="line">x = np.linspace(-0.4, 0.7, num=N*D).reshape(N, D)</span><br><span class="line">prev_h = np.linspace(-0.2, 0.5, num=N*H).reshape(N, H)</span><br><span class="line">Wx = np.linspace(-0.1, 0.9, num=D*H).reshape(D, H)</span><br><span class="line">Wh = np.linspace(-0.3, 0.7, num=H*H).reshape(H, H)</span><br><span class="line">b = np.linspace(-0.2, 0.4, num=H)</span><br><span class="line"></span><br><span class="line">next_h, _ = rnn_step_forward(x, prev_h, Wx, Wh, b)</span><br><span class="line">expected_next_h = np.asarray([</span><br><span class="line">  [-0.58172089, -0.50182032, -0.41232771, -0.31410098],</span><br><span class="line">  [ 0.66854692,  0.79562378,  0.87755553,  0.92795967],</span><br><span class="line">  [ 0.97934501,  0.99144213,  0.99646691,  0.99854353]])</span><br><span class="line"></span><br><span class="line">print(&#x27;next_h error: &#x27;, rel_error(expected_next_h, next_h))</span><br></pre></td></tr></table></figure>

<p><img src="/images/CS231n_Assignment3_Image_Captioning_with_RNNs/4.png" alt="4"></p>
<h3 id="Vanilla-RNN-step-backward"><a href="#Vanilla-RNN-step-backward" class="headerlink" title="Vanilla RNN: step backward"></a>Vanilla RNN: step backward</h3><p>同理在runn_layers.py完成runn_step_backward反向算法，并在这里检验误差。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">from cs231n.rnn_layers import rnn_step_forward, rnn_step_backward</span><br><span class="line">np.random.seed(231)</span><br><span class="line">N, D, H = 4, 5, 6</span><br><span class="line">x = np.random.randn(N, D)</span><br><span class="line">h = np.random.randn(N, H)</span><br><span class="line">Wx = np.random.randn(D, H)</span><br><span class="line">Wh = np.random.randn(H, H)</span><br><span class="line">b = np.random.randn(H)</span><br><span class="line"></span><br><span class="line">out, cache = rnn_step_forward(x, h, Wx, Wh, b)</span><br><span class="line"></span><br><span class="line">dnext_h = np.random.randn(*out.shape)</span><br><span class="line"></span><br><span class="line">fx = lambda x: rnn_step_forward(x, h, Wx, Wh, b)[0]</span><br><span class="line">fh = lambda prev_h: rnn_step_forward(x, h, Wx, Wh, b)[0]</span><br><span class="line">fWx = lambda Wx: rnn_step_forward(x, h, Wx, Wh, b)[0]</span><br><span class="line">fWh = lambda Wh: rnn_step_forward(x, h, Wx, Wh, b)[0]</span><br><span class="line">fb = lambda b: rnn_step_forward(x, h, Wx, Wh, b)[0]</span><br><span class="line"></span><br><span class="line">dx_num = eval_numerical_gradient_array(fx, x, dnext_h)</span><br><span class="line">dprev_h_num = eval_numerical_gradient_array(fh, h, dnext_h)</span><br><span class="line">dWx_num = eval_numerical_gradient_array(fWx, Wx, dnext_h)</span><br><span class="line">dWh_num = eval_numerical_gradient_array(fWh, Wh, dnext_h)</span><br><span class="line">db_num = eval_numerical_gradient_array(fb, b, dnext_h)</span><br><span class="line"></span><br><span class="line">dx, dprev_h, dWx, dWh, db = rnn_step_backward(dnext_h, cache)</span><br><span class="line"></span><br><span class="line">print(&#x27;dx error: &#x27;, rel_error(dx_num, dx))</span><br><span class="line">print(&#x27;dprev_h error: &#x27;, rel_error(dprev_h_num, dprev_h))</span><br><span class="line">print(&#x27;dWx error: &#x27;, rel_error(dWx_num, dWx))</span><br><span class="line">print(&#x27;dWh error: &#x27;, rel_error(dWh_num, dWh))</span><br><span class="line">print(&#x27;db error: &#x27;, rel_error(db_num, db))</span><br></pre></td></tr></table></figure>

<p><img src="/images/CS231n_Assignment3_Image_Captioning_with_RNNs/5.png" alt="5"></p>
<h3 id="Vanilla-RNN-forward"><a href="#Vanilla-RNN-forward" class="headerlink" title="Vanilla RNN: forward"></a>Vanilla RNN: forward</h3><p>在rnn_layers.py中完成rnn_forward即朴素的RNN正反向传播，并检验误差。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">N, T, D, H = 2, 3, 4, 5</span><br><span class="line"></span><br><span class="line">x = np.linspace(-0.1, 0.3, num=N*T*D).reshape(N, T, D)</span><br><span class="line">h0 = np.linspace(-0.3, 0.1, num=N*H).reshape(N, H)</span><br><span class="line">Wx = np.linspace(-0.2, 0.4, num=D*H).reshape(D, H)</span><br><span class="line">Wh = np.linspace(-0.4, 0.1, num=H*H).reshape(H, H)</span><br><span class="line">b = np.linspace(-0.7, 0.1, num=H)</span><br><span class="line"></span><br><span class="line">h, _ = rnn_forward(x, h0, Wx, Wh, b)</span><br><span class="line">expected_h = np.asarray([</span><br><span class="line">  [</span><br><span class="line">    [-0.42070749, -0.27279261, -0.11074945,  0.05740409,  0.22236251],</span><br><span class="line">    [-0.39525808, -0.22554661, -0.0409454,   0.14649412,  0.32397316],</span><br><span class="line">    [-0.42305111, -0.24223728, -0.04287027,  0.15997045,  0.35014525],</span><br><span class="line">  ],</span><br><span class="line">  [</span><br><span class="line">    [-0.55857474, -0.39065825, -0.19198182,  0.02378408,  0.23735671],</span><br><span class="line">    [-0.27150199, -0.07088804,  0.13562939,  0.33099728,  0.50158768],</span><br><span class="line">    [-0.51014825, -0.30524429, -0.06755202,  0.17806392,  0.40333043]]])</span><br><span class="line">print(&#x27;h error: &#x27;, rel_error(expected_h, h))</span><br></pre></td></tr></table></figure>

<p><img src="/images/CS231n_Assignment3_Image_Captioning_with_RNNs/6.png" alt="6"></p>
<h3 id="Vanilla-RNN-backward"><a href="#Vanilla-RNN-backward" class="headerlink" title="Vanilla RNN: backward"></a>Vanilla RNN: backward</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(231)</span><br><span class="line"></span><br><span class="line">N, D, T, H = 2, 3, 10, 5</span><br><span class="line"></span><br><span class="line">x = np.random.randn(N, T, D)</span><br><span class="line">h0 = np.random.randn(N, H)</span><br><span class="line">Wx = np.random.randn(D, H)</span><br><span class="line">Wh = np.random.randn(H, H)</span><br><span class="line">b = np.random.randn(H)</span><br><span class="line"></span><br><span class="line">out, cache = rnn_forward(x, h0, Wx, Wh, b)</span><br><span class="line"></span><br><span class="line">dout = np.random.randn(*out.shape)</span><br><span class="line"></span><br><span class="line">dx, dh0, dWx, dWh, db = rnn_backward(dout, cache)</span><br><span class="line"></span><br><span class="line">fx = lambda x: rnn_forward(x, h0, Wx, Wh, b)[0]</span><br><span class="line">fh0 = lambda h0: rnn_forward(x, h0, Wx, Wh, b)[0]</span><br><span class="line">fWx = lambda Wx: rnn_forward(x, h0, Wx, Wh, b)[0]</span><br><span class="line">fWh = lambda Wh: rnn_forward(x, h0, Wx, Wh, b)[0]</span><br><span class="line">fb = lambda b: rnn_forward(x, h0, Wx, Wh, b)[0]</span><br><span class="line"></span><br><span class="line">dx_num = eval_numerical_gradient_array(fx, x, dout)</span><br><span class="line">dh0_num = eval_numerical_gradient_array(fh0, h0, dout)</span><br><span class="line">dWx_num = eval_numerical_gradient_array(fWx, Wx, dout)</span><br><span class="line">dWh_num = eval_numerical_gradient_array(fWh, Wh, dout)</span><br><span class="line">db_num = eval_numerical_gradient_array(fb, b, dout)</span><br><span class="line"></span><br><span class="line">print(&#x27;dx error: &#x27;, rel_error(dx_num, dx))</span><br><span class="line">print(&#x27;dh0 error: &#x27;, rel_error(dh0_num, dh0))</span><br><span class="line">print(&#x27;dWx error: &#x27;, rel_error(dWx_num, dWx))</span><br><span class="line">print(&#x27;dWh error: &#x27;, rel_error(dWh_num, dWh))</span><br><span class="line">print(&#x27;db error: &#x27;, rel_error(db_num, db))</span><br></pre></td></tr></table></figure>

<p><img src="/images/CS231n_Assignment3_Image_Captioning_with_RNNs/7.png" alt="7"></p>
<h3 id="Word-embedding-forward"><a href="#Word-embedding-forward" class="headerlink" title="Word embedding: forward"></a>Word embedding: forward</h3><p>在深度学习系统中，我们通常使用向量来表示单词。词汇表中的每个单词将与一个向量相关联，这些向量将与系统的其他部分一起学习。在rnn_layers.py中完成单词向量嵌入的正反向传播，并再次检验误差</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">N, T, V, D = 2, 4, 5, 3</span><br><span class="line"></span><br><span class="line">x = np.asarray([[0, 3, 1, 2], [2, 1, 0, 3]])</span><br><span class="line">W = np.linspace(0, 1, num=V*D).reshape(V, D)</span><br><span class="line"></span><br><span class="line">out, _ = word_embedding_forward(x, W)</span><br><span class="line">expected_out = np.asarray([</span><br><span class="line"> [[ 0.,          0.07142857,  0.14285714],</span><br><span class="line">  [ 0.64285714,  0.71428571,  0.78571429],</span><br><span class="line">  [ 0.21428571,  0.28571429,  0.35714286],</span><br><span class="line">  [ 0.42857143,  0.5,         0.57142857]],</span><br><span class="line"> [[ 0.42857143,  0.5,         0.57142857],</span><br><span class="line">  [ 0.21428571,  0.28571429,  0.35714286],</span><br><span class="line">  [ 0.,          0.07142857,  0.14285714],</span><br><span class="line">  [ 0.64285714,  0.71428571,  0.78571429]]])</span><br><span class="line"></span><br><span class="line">print(&#x27;out error: &#x27;, rel_error(expected_out, out))	</span><br></pre></td></tr></table></figure>

<p><img src="/images/CS231n_Assignment3_Image_Captioning_with_RNNs/8.png" alt="8"></p>
<h3 id="Word-embedding-backward"><a href="#Word-embedding-backward" class="headerlink" title="Word embedding: backward"></a>Word embedding: backward</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(231)</span><br><span class="line"></span><br><span class="line">N, T, V, D = 50, 3, 5, 6</span><br><span class="line">x = np.random.randint(V, size=(N, T))</span><br><span class="line">W = np.random.randn(V, D)</span><br><span class="line"></span><br><span class="line">out, cache = word_embedding_forward(x, W)</span><br><span class="line">dout = np.random.randn(*out.shape)</span><br><span class="line">dW = word_embedding_backward(dout, cache)</span><br><span class="line"></span><br><span class="line">f = lambda W: word_embedding_forward(x, W)[0]</span><br><span class="line">dW_num = eval_numerical_gradient_array(f, W, dout)</span><br><span class="line"></span><br><span class="line">print(&#x27;dW error: &#x27;, rel_error(dW, dW_num))</span><br></pre></td></tr></table></figure>

<p><img src="/images/CS231n_Assignment3_Image_Captioning_with_RNNs/9.png" alt="9"></p>
<h3 id="Temporal-Affine-layer"><a href="#Temporal-Affine-layer" class="headerlink" title="Temporal Affine layer"></a>Temporal Affine layer</h3><p>像assignment2中的affine层一样，获得每一步RNN隐藏向量转换为词汇表中每个单词的得分，temporal_affine_forward和temporal_affine_backward已经在rnn_layers.py中完成。运行计算误差。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(231)</span><br><span class="line"></span><br><span class="line"># Gradient check for temporal affine layer</span><br><span class="line">N, T, D, M = 2, 3, 4, 5</span><br><span class="line">x = np.random.randn(N, T, D)</span><br><span class="line">w = np.random.randn(D, M)</span><br><span class="line">b = np.random.randn(M)</span><br><span class="line"></span><br><span class="line">out, cache = temporal_affine_forward(x, w, b)</span><br><span class="line"></span><br><span class="line">dout = np.random.randn(*out.shape)</span><br><span class="line"></span><br><span class="line">fx = lambda x: temporal_affine_forward(x, w, b)[0]</span><br><span class="line">fw = lambda w: temporal_affine_forward(x, w, b)[0]</span><br><span class="line">fb = lambda b: temporal_affine_forward(x, w, b)[0]</span><br><span class="line"></span><br><span class="line">dx_num = eval_numerical_gradient_array(fx, x, dout)</span><br><span class="line">dw_num = eval_numerical_gradient_array(fw, w, dout)</span><br><span class="line">db_num = eval_numerical_gradient_array(fb, b, dout)</span><br><span class="line"></span><br><span class="line">dx, dw, db = temporal_affine_backward(dout, cache)</span><br><span class="line"></span><br><span class="line">print(&#x27;dx error: &#x27;, rel_error(dx_num, dx))</span><br><span class="line">print(&#x27;dw error: &#x27;, rel_error(dw_num, dw))</span><br><span class="line">print(&#x27;db error: &#x27;, rel_error(db_num, db))</span><br></pre></td></tr></table></figure>

<p><img src="/images/CS231n_Assignment3_Image_Captioning_with_RNNs/10.png" alt="10"></p>
<h3 id="Temporal-Softmax-loss"><a href="#Temporal-Softmax-loss" class="headerlink" title="Temporal Softmax loss"></a>Temporal Softmax loss</h3><p>rnn_layers.py中已经完成了temporal_softmax_loss函数，因此这里也只需要直接运行检测误差即可。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># Sanity check for temporal softmax loss</span><br><span class="line">from cs231n.rnn_layers import temporal_softmax_loss</span><br><span class="line"></span><br><span class="line">N, T, V = 100, 1, 10</span><br><span class="line"></span><br><span class="line">def check_loss(N, T, V, p):</span><br><span class="line">    x = 0.001 * np.random.randn(N, T, V)</span><br><span class="line">    y = np.random.randint(V, size=(N, T))</span><br><span class="line">    mask = np.random.rand(N, T) &lt;= p</span><br><span class="line">    print(temporal_softmax_loss(x, y, mask)[0])</span><br><span class="line">  </span><br><span class="line">check_loss(100, 1, 10, 1.0)   # Should be about 2.3</span><br><span class="line">check_loss(100, 10, 10, 1.0)  # Should be about 23</span><br><span class="line">check_loss(5000, 10, 10, 0.1) # Should be about 2.3</span><br><span class="line"></span><br><span class="line"># Gradient check for temporal softmax loss</span><br><span class="line">N, T, V = 7, 8, 9</span><br><span class="line"></span><br><span class="line">x = np.random.randn(N, T, V)</span><br><span class="line">y = np.random.randint(V, size=(N, T))</span><br><span class="line">mask = (np.random.rand(N, T) &gt; 0.5)</span><br><span class="line"></span><br><span class="line">loss, dx = temporal_softmax_loss(x, y, mask, verbose=False)</span><br><span class="line"></span><br><span class="line">dx_num = eval_numerical_gradient(lambda x: temporal_softmax_loss(x, y, mask)[0], x, verbose=False)</span><br><span class="line"></span><br><span class="line">print(&#x27;dx error: &#x27;, rel_error(dx, dx_num))</span><br></pre></td></tr></table></figure>

<p><img src="/images/CS231n_Assignment3_Image_Captioning_with_RNNs/11.png" alt="11"></p>
<h3 id="RNN-for-image-captioning"><a href="#RNN-for-image-captioning" class="headerlink" title="RNN for image captioning"></a>RNN for image captioning</h3><p>在&#x2F;classifiers中的rnn.py中完成朴素的RNN训练模式，并在这里检验误差</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">N, D, W, H = 10, 20, 30, 40</span><br><span class="line">word_to_idx = &#123;&#x27;&lt;NULL&gt;&#x27;: 0, &#x27;cat&#x27;: 2, &#x27;dog&#x27;: 3&#125;</span><br><span class="line">V = len(word_to_idx)</span><br><span class="line">T = 13</span><br><span class="line"></span><br><span class="line">model = CaptioningRNN(word_to_idx,</span><br><span class="line">          input_dim=D,</span><br><span class="line">          wordvec_dim=W,</span><br><span class="line">          hidden_dim=H,</span><br><span class="line">          cell_type=&#x27;rnn&#x27;,</span><br><span class="line">          dtype=np.float64)</span><br><span class="line"></span><br><span class="line"># Set all model parameters to fixed values</span><br><span class="line">for k, v in model.params.items():</span><br><span class="line">    model.params[k] = np.linspace(-1.4, 1.3, num=v.size).reshape(*v.shape)</span><br><span class="line"></span><br><span class="line">features = np.linspace(-1.5, 0.3, num=(N * D)).reshape(N, D)</span><br><span class="line">captions = (np.arange(N * T) % V).reshape(N, T)</span><br><span class="line"></span><br><span class="line">loss, grads = model.loss(features, captions)</span><br><span class="line">expected_loss = 9.83235591003</span><br><span class="line"></span><br><span class="line">print(&#x27;loss: &#x27;, loss)</span><br><span class="line">print(&#x27;expected loss: &#x27;, expected_loss)</span><br><span class="line">print(&#x27;difference: &#x27;, abs(loss - expected_loss))</span><br></pre></td></tr></table></figure>

<p><img src="/images/CS231n_Assignment3_Image_Captioning_with_RNNs/12.png" alt="12"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(231)</span><br><span class="line"></span><br><span class="line">batch_size = 2</span><br><span class="line">timesteps = 3</span><br><span class="line">input_dim = 4</span><br><span class="line">wordvec_dim = 5</span><br><span class="line">hidden_dim = 6</span><br><span class="line">word_to_idx = &#123;&#x27;&lt;NULL&gt;&#x27;: 0, &#x27;cat&#x27;: 2, &#x27;dog&#x27;: 3&#125;</span><br><span class="line">vocab_size = len(word_to_idx)</span><br><span class="line"></span><br><span class="line">captions = np.random.randint(vocab_size, size=(batch_size, timesteps))</span><br><span class="line">features = np.random.randn(batch_size, input_dim)</span><br><span class="line"></span><br><span class="line">model = CaptioningRNN(word_to_idx,</span><br><span class="line">          input_dim=input_dim,</span><br><span class="line">          wordvec_dim=wordvec_dim,</span><br><span class="line">          hidden_dim=hidden_dim,</span><br><span class="line">          cell_type=&#x27;rnn&#x27;,</span><br><span class="line">          dtype=np.float64,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">loss, grads = model.loss(features, captions)</span><br><span class="line"></span><br><span class="line">for param_name in sorted(grads):</span><br><span class="line">    f = lambda _: model.loss(features, captions)[0]</span><br><span class="line">    param_grad_num = eval_numerical_gradient(f, model.params[param_name], verbose=False, h=1e-6)</span><br><span class="line">    e = rel_error(param_grad_num, grads[param_name])</span><br><span class="line">    print(&#x27;%s relative error: %e&#x27; % (param_name, e))</span><br></pre></td></tr></table></figure>

<p><img src="/images/CS231n_Assignment3_Image_Captioning_with_RNNs/13.png" alt="13"></p>
<h3 id="Overfit-small-data"><a href="#Overfit-small-data" class="headerlink" title="Overfit small data"></a>Overfit small data</h3><p>选择比较少的数据集训练，在这里发现model只是说选择训练的方式，比如说两层神经网络，三层卷积神经网络等，不同的模型有不同的训练方式，计算的梯度方式是不同的。这里选择的是朴素的RNN模型，然后选择较小的数据集，构建Solver训练数据集，并可视化损失。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(231)</span><br><span class="line"></span><br><span class="line">small_data = load_coco_data(max_train=50)</span><br><span class="line"></span><br><span class="line">small_rnn_model = CaptioningRNN(</span><br><span class="line">          cell_type=&#x27;rnn&#x27;,</span><br><span class="line">          word_to_idx=data[&#x27;word_to_idx&#x27;],</span><br><span class="line">          input_dim=data[&#x27;train_features&#x27;].shape[1],</span><br><span class="line">          hidden_dim=512,</span><br><span class="line">          wordvec_dim=256,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">small_rnn_solver = CaptioningSolver(small_rnn_model, small_data,</span><br><span class="line">           update_rule=&#x27;adam&#x27;,</span><br><span class="line">           num_epochs=50,</span><br><span class="line">           batch_size=25,</span><br><span class="line">           optim_config=&#123;</span><br><span class="line">             &#x27;learning_rate&#x27;: 5e-3,</span><br><span class="line">           &#125;,</span><br><span class="line">           lr_decay=0.95,</span><br><span class="line">           verbose=True, print_every=10,</span><br><span class="line">         )</span><br><span class="line"></span><br><span class="line">small_rnn_solver.train()</span><br><span class="line"></span><br><span class="line"># Plot the training losses</span><br><span class="line">plt.plot(small_rnn_solver.loss_history)</span><br><span class="line">plt.xlabel(&#x27;Iteration&#x27;)</span><br><span class="line">plt.ylabel(&#x27;Loss&#x27;)</span><br><span class="line">plt.title(&#x27;Training loss history&#x27;)</span><br><span class="line">plt.show()	</span><br></pre></td></tr></table></figure>

<p><img src="/images/CS231n_Assignment3_Image_Captioning_with_RNNs/14.png" alt="img"></p>
<h3 id="Test-time-sampling"><a href="#Test-time-sampling" class="headerlink" title="Test-time sampling"></a>Test-time sampling</h3><p>没有VPN~~~~连接不了外网~~~~~</p>
<h1 id="rnn-layers-py"><a href="#rnn-layers-py" class="headerlink" title="rnn_layers.py"></a>rnn_layers.py</h1><p>在本段代码中完成rnn的单步前向传播和反向传播代码</p>
<p><img src="/images/CS231n_Assignment3_Image_Captioning_with_RNNs/2.png" alt="2"></p>
<p>如上所示，传播的公式为：<br>$$<br>h_t&#x3D;tanh(W_hh × h_t-1+W_xh × x_t+b)<br>$$<br>上图中漏了偏置项，在此加上，并且反向传播中，对tanhx求导的公式如下：</p>
<p><img src="/images/CS231n_Assignment3_Image_Captioning_with_RNNs/1.png" alt="1"></p>
<p>正文段如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">def rnn_step_forward(x, prev_h, Wx, Wh, b):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Run the forward pass for a single timestep of a vanilla RNN that uses a tanh</span><br><span class="line">    activation function.</span><br><span class="line"></span><br><span class="line">    The input data has dimension D, the hidden state has dimension H, and we use</span><br><span class="line">    a minibatch size of N.</span><br><span class="line"></span><br><span class="line">    Inputs:</span><br><span class="line">    - x: Input data for this timestep, of shape (N, D).</span><br><span class="line">    - prev_h: Hidden state from previous timestep, of shape (N, H)</span><br><span class="line">    - Wx: Weight matrix for input-to-hidden connections, of shape (D, H)</span><br><span class="line">    - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H)</span><br><span class="line">    - b: Biases of shape (H,)</span><br><span class="line"></span><br><span class="line">    Returns a tuple of:</span><br><span class="line">    - next_h: Next hidden state, of shape (N, H)</span><br><span class="line">    - cache: Tuple of values needed for the backward pass.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    next_h, cache = None, None</span><br><span class="line">    ##############################################################################</span><br><span class="line">    # TODO: Implement a single forward step for the vanilla RNN. Store the next  #</span><br><span class="line">    # hidden state and any values you need for the backward pass in the next_h   #</span><br><span class="line">    # and cache variables respectively.                                          #</span><br><span class="line">    ##############################################################################</span><br><span class="line">    next_h=np.tanh(prev_h.dot(Wh)+x.dot(Wx)+b)</span><br><span class="line">    cache=x,prev_h,Wx,Wh,next_h</span><br><span class="line">    pass</span><br><span class="line">    ##############################################################################</span><br><span class="line">    #                               END OF YOUR CODE                             #</span><br><span class="line">    ##############################################################################</span><br><span class="line">    return next_h, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def rnn_step_backward(dnext_h, cache):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Backward pass for a single timestep of a vanilla RNN.</span><br><span class="line"></span><br><span class="line">    Inputs:</span><br><span class="line">    - dnext_h: Gradient of loss with respect to next hidden state</span><br><span class="line">    - cache: Cache object from the forward pass</span><br><span class="line"></span><br><span class="line">    Returns a tuple of:</span><br><span class="line">    - dx: Gradients of input data, of shape (N, D)</span><br><span class="line">    - dprev_h: Gradients of previous hidden state, of shape (N, H)</span><br><span class="line">    - dWx: Gradients of input-to-hidden weights, of shape (D, H)</span><br><span class="line">    - dWh: Gradients of hidden-to-hidden weights, of shape (H, H)</span><br><span class="line">    - db: Gradients of bias vector, of shape (H,)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    dx, dprev_h, dWx, dWh, db = None, None, None, None, None</span><br><span class="line">    ##############################################################################</span><br><span class="line">    # TODO: Implement the backward pass for a single step of a vanilla RNN.      #</span><br><span class="line">    #                                                                            #</span><br><span class="line">    # HINT: For the tanh function, you can compute the local derivative in terms #</span><br><span class="line">    # of the output value from tanh.                                             #</span><br><span class="line">    ##############################################################################</span><br><span class="line">    x,prev_h,Wx,Wh,next_h=cache</span><br><span class="line">    dtanh_h=dnext_h*(1-next_h**2)</span><br><span class="line">    dx=dtanh_h.dot(Wx.T)</span><br><span class="line">    dprev_h=dtanh_h.dot(Wh.T)     #[dprev_h]=[N,H]  dnext_h[N,H]   Wh[H,H]</span><br><span class="line">    dWx=x.T.dot(dtanh_h)          #dWx[D,H]  dnext_h[N,H] x[N,D]</span><br><span class="line">    dWh=prev_h.T.dot(dtanh_h)     #dWh [H,H]  prev_h[N,H] dnext_h[N,H]</span><br><span class="line">    db=np.sum(dtanh_h,axis=0)</span><br><span class="line">                        </span><br><span class="line">    pass</span><br><span class="line">    ##############################################################################</span><br><span class="line">    #                               END OF YOUR CODE                             #</span><br><span class="line">    ##############################################################################</span><br><span class="line">    return dx, dprev_h, dWx, dWh, db</span><br></pre></td></tr></table></figure>

<p>这里需要注意的是cache的类型</p>
<p>cache&#x3D;[],因此需要cache.append往里面加数据</p>
<p>在反向传播中，需要注意的是求的dx[N,T,D]是所有情况下的值，因此不需要累加，h0同样如此但是因为中途需要变更h，所以要在式子中体现，而dWx，dWh，db不同，每个单步中求得的是单步的导数，因此需要对此进行累加.</p>
<p>这里需要再次强调的是数组的形状需要初始化！！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">def rnn_forward(x, h0, Wx, Wh, b):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Run a vanilla RNN forward on an entire sequence of data. We assume an input</span><br><span class="line">    sequence composed of T vectors, each of dimension D. The RNN uses a hidden</span><br><span class="line">    size of H, and we work over a minibatch containing N sequences. After running</span><br><span class="line">    the RNN forward, we return the hidden states for all timesteps.</span><br><span class="line"></span><br><span class="line">    Inputs:</span><br><span class="line">    - x: Input data for the entire timeseries, of shape (N, T, D).</span><br><span class="line">    - h0: Initial hidden state, of shape (N, H)</span><br><span class="line">    - Wx: Weight matrix for input-to-hidden connections, of shape (D, H)</span><br><span class="line">    - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H)</span><br><span class="line">    - b: Biases of shape (H,)</span><br><span class="line"></span><br><span class="line">    Returns a tuple of:</span><br><span class="line">    - h: Hidden states for the entire timeseries, of shape (N, T, H).</span><br><span class="line">    - cache: Values needed in the backward pass</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    h, cache = None, None</span><br><span class="line">    ##############################################################################</span><br><span class="line">    # TODO: Implement forward pass for a vanilla RNN running on a sequence of    #</span><br><span class="line">    # input data. You should use the rnn_step_forward function that you defined  #</span><br><span class="line">    # above. You can use a for loop to help compute the forward pass.            #</span><br><span class="line">    ##############################################################################</span><br><span class="line">    N,T,D=x.shape</span><br><span class="line">    _,H=h0.shape</span><br><span class="line">    h=np.zeros((N,T,H))</span><br><span class="line">    prev_h=h0</span><br><span class="line">    cache=[]</span><br><span class="line">    for i in range(T):</span><br><span class="line">        h[:,i,:],cac=rnn_step_forward(x[:,i,:],prev_h,Wx,Wh,b)</span><br><span class="line">        #cache[i]=x[:,i,:],h[i],Wx,Wh,h[i+1]</span><br><span class="line">        prev_h=h[:,i,:]</span><br><span class="line">        cache.append(cac)</span><br><span class="line">    pass</span><br><span class="line">    ##############################################################################</span><br><span class="line">    #                               END OF YOUR CODE                             #</span><br><span class="line">    ##############################################################################</span><br><span class="line">    return h, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def rnn_backward(dh, cache):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Compute the backward pass for a vanilla RNN over an entire sequence of data.</span><br><span class="line"></span><br><span class="line">    Inputs:</span><br><span class="line">    - dh: Upstream gradients of all hidden states, of shape (N, T, H)</span><br><span class="line"></span><br><span class="line">    Returns a tuple of:</span><br><span class="line">    - dx: Gradient of inputs, of shape (N, T, D)</span><br><span class="line">    - dh0: Gradient of initial hidden state, of shape (N, H)</span><br><span class="line">    - dWx: Gradient of input-to-hidden weights, of shape (D, H)</span><br><span class="line">    - dWh: Gradient of hidden-to-hidden weights, of shape (H, H)</span><br><span class="line">    - db: Gradient of biases, of shape (H,)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    dx, dh0, dWx, dWh, db = None, None, None, None, None</span><br><span class="line">    ##############################################################################</span><br><span class="line">    # TODO: Implement the backward pass for a vanilla RNN running an entire      #</span><br><span class="line">    # sequence of data. You should use the rnn_step_backward function that you   #</span><br><span class="line">    # defined above. You can use a for loop to help compute the backward pass.   #</span><br><span class="line">    ##############################################################################</span><br><span class="line">    T=len(cache)</span><br><span class="line">    N,D=cache[0][0].shape</span><br><span class="line">    dx=np.zeros((N,T,D))</span><br><span class="line">    dWx,dWh,db=0,0,0</span><br><span class="line">    dprev_h=0</span><br><span class="line">    for i in range(T,0,-1):</span><br><span class="line">        dx[:,i-1,:],dprev_h,dWxi,dWhi,dbi=rnn_step_backward(dh[:,i-1,:]+dprev_h,cache[i-1])</span><br><span class="line">        dWx+=dWxi</span><br><span class="line">        dWh+=dWhi</span><br><span class="line">        db+=dbi</span><br><span class="line">        </span><br><span class="line">    pass</span><br><span class="line">    dh0=dprev_h</span><br><span class="line">    ##############################################################################</span><br><span class="line">    #                               END OF YOUR CODE                             #</span><br><span class="line">    ##############################################################################</span><br><span class="line">    return dx, dh0, dWx, dWh, db</span><br></pre></td></tr></table></figure>

<p>正向传播的单词嵌入成向量好理解，反向传播有点难以理解。。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">def word_embedding_forward(x, W):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Forward pass for word embeddings. We operate on minibatches of size N where</span><br><span class="line">    each sequence has length T. We assume a vocabulary of V words, assigning each</span><br><span class="line">    to a vector of dimension D.</span><br><span class="line"></span><br><span class="line">    Inputs:</span><br><span class="line">    - x: Integer array of shape (N, T) giving indices of words. Each element idx</span><br><span class="line">      of x muxt be in the range 0 &lt;= idx &lt; V.</span><br><span class="line">    - W: Weight matrix of shape (V, D) giving word vectors for all words.</span><br><span class="line"></span><br><span class="line">    Returns a tuple of:</span><br><span class="line">    - out: Array of shape (N, T, D) giving word vectors for all input words.</span><br><span class="line">    - cache: Values needed for the backward pass</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    out, cache = None, None</span><br><span class="line">    ##############################################################################</span><br><span class="line">    # TODO: Implement the forward pass for word embeddings.                      #</span><br><span class="line">    #                                                                            #</span><br><span class="line">    # HINT: This can be done in one line using NumPy&#x27;s array indexing.           #</span><br><span class="line">    ##############################################################################</span><br><span class="line">    out = W[x, :]</span><br><span class="line">    cache = (x, W.shape)</span><br><span class="line">    pass</span><br><span class="line">    ##############################################################################</span><br><span class="line">    #                               END OF YOUR CODE                             #</span><br><span class="line">    ##############################################################################</span><br><span class="line">    return out, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def word_embedding_backward(dout, cache):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Backward pass for word embeddings. We cannot back-propagate into the words</span><br><span class="line">    since they are integers, so we only return gradient for the word embedding</span><br><span class="line">    matrix.</span><br><span class="line"></span><br><span class="line">    HINT: Look up the function np.add.at</span><br><span class="line"></span><br><span class="line">    Inputs:</span><br><span class="line">    - dout: Upstream gradients of shape (N, T, D)</span><br><span class="line">    - cache: Values from the forward pass</span><br><span class="line"></span><br><span class="line">    Returns:</span><br><span class="line">    - dW: Gradient of word embedding matrix, of shape (V, D).</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    dW = None</span><br><span class="line">    ##############################################################################</span><br><span class="line">    # TODO: Implement the backward pass for word embeddings.                     #</span><br><span class="line">    #                                                                            #</span><br><span class="line">    # Note that Words can appear more than once in a sequence.                   #</span><br><span class="line">    # HINT: Look up the function np.add.at                                       #</span><br><span class="line">    ##############################################################################</span><br><span class="line">    x,shp=cache</span><br><span class="line">    dW=np.zeros(shp)</span><br><span class="line">    np.add.at(dW,x,dout)</span><br><span class="line">    pass</span><br><span class="line">    ##############################################################################</span><br><span class="line">    #                               END OF YOUR CODE                             #</span><br><span class="line">    ##############################################################################</span><br><span class="line">    return dW</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">def temporal_affine_forward(x, w, b):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Forward pass for a temporal affine layer. The input is a set of D-dimensional</span><br><span class="line">    vectors arranged into a minibatch of N timeseries, each of length T. We use</span><br><span class="line">    an affine function to transform each of those vectors into a new vector of</span><br><span class="line">    dimension M.</span><br><span class="line"></span><br><span class="line">    Inputs:</span><br><span class="line">    - x: Input data of shape (N, T, D)</span><br><span class="line">    - w: Weights of shape (D, M)</span><br><span class="line">    - b: Biases of shape (M,)</span><br><span class="line"></span><br><span class="line">    Returns a tuple of:</span><br><span class="line">    - out: Output data of shape (N, T, M)</span><br><span class="line">    - cache: Values needed for the backward pass</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    N, T, D = x.shape</span><br><span class="line">    M = b.shape[0]</span><br><span class="line">    out = x.reshape(N * T, D).dot(w).reshape(N, T, M) + b</span><br><span class="line">    cache = x, w, b, out</span><br><span class="line">    return out, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def temporal_affine_backward(dout, cache):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Backward pass for temporal affine layer.</span><br><span class="line"></span><br><span class="line">    Input:</span><br><span class="line">    - dout: Upstream gradients of shape (N, T, M)</span><br><span class="line">    - cache: Values from forward pass</span><br><span class="line"></span><br><span class="line">    Returns a tuple of:</span><br><span class="line">    - dx: Gradient of input, of shape (N, T, D)</span><br><span class="line">    - dw: Gradient of weights, of shape (D, M)</span><br><span class="line">    - db: Gradient of biases, of shape (M,)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x, w, b, out = cache</span><br><span class="line">    N, T, D = x.shape</span><br><span class="line">    M = b.shape[0]</span><br><span class="line"></span><br><span class="line">    dx = dout.reshape(N * T, M).dot(w.T).reshape(N, T, D)</span><br><span class="line">    dw = dout.reshape(N * T, M).T.dot(x.reshape(N * T, D)).T</span><br><span class="line">    db = dout.sum(axis=(0, 1))</span><br><span class="line"></span><br><span class="line">    return dx, dw, db</span><br></pre></td></tr></table></figure>

<p>用softmax来求交叉熵损失，但是因为标题的长度是不一定的，所以引入mask掩膜数组，该数组告诉它是否要计算损失，因为当某些单词填入NULL是为了保证长度一样，但是是不计算损失的。其他部分和softmax的求法完全相同，就是多了一个mask矩阵</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">def temporal_softmax_loss(x, y, mask, verbose=False):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    A temporal version of softmax loss for use in RNNs. We assume that we are</span><br><span class="line">    making predictions over a vocabulary of size V for each timestep of a</span><br><span class="line">    timeseries of length T, over a minibatch of size N. The input x gives scores</span><br><span class="line">    for all vocabulary elements at all timesteps, and y gives the indices of the</span><br><span class="line">    ground-truth element at each timestep. We use a cross-entropy loss at each</span><br><span class="line">    timestep, summing the loss over all timesteps and averaging across the</span><br><span class="line">    minibatch.</span><br><span class="line"></span><br><span class="line">    As an additional complication, we may want to ignore the model output at some</span><br><span class="line">    timesteps, since sequences of different length may have been combined into a</span><br><span class="line">    minibatch and padded with NULL tokens. The optional mask argument tells us</span><br><span class="line">    which elements should contribute to the loss.</span><br><span class="line"></span><br><span class="line">    Inputs:</span><br><span class="line">    - x: Input scores, of shape (N, T, V)</span><br><span class="line">    - y: Ground-truth indices, of shape (N, T) where each element is in the range</span><br><span class="line">         0 &lt;= y[i, t] &lt; V</span><br><span class="line">    - mask: Boolean array of shape (N, T) where mask[i, t] tells whether or not</span><br><span class="line">      the scores at x[i, t] should contribute to the loss.</span><br><span class="line"></span><br><span class="line">    Returns a tuple of:</span><br><span class="line">    - loss: Scalar giving loss</span><br><span class="line">    - dx: Gradient of loss with respect to scores x.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    N, T, V = x.shape</span><br><span class="line"></span><br><span class="line">    x_flat = x.reshape(N * T, V)</span><br><span class="line">    y_flat = y.reshape(N * T)</span><br><span class="line">    mask_flat = mask.reshape(N * T)</span><br><span class="line"></span><br><span class="line">    probs = np.exp(x_flat - np.max(x_flat, axis=1, keepdims=True))</span><br><span class="line">    probs /= np.sum(probs, axis=1, keepdims=True)</span><br><span class="line">    loss = -np.sum(mask_flat * np.log(probs[np.arange(N * T), y_flat])) / N</span><br><span class="line">    dx_flat = probs.copy()</span><br><span class="line">    dx_flat[np.arange(N * T), y_flat] -= 1</span><br><span class="line">    dx_flat /= N</span><br><span class="line">    dx_flat *= mask_flat[:, None]</span><br><span class="line"></span><br><span class="line">    if verbose: print(&#x27;dx_flat: &#x27;, dx_flat.shape)</span><br><span class="line"></span><br><span class="line">    dx = dx_flat.reshape(N, T, V)</span><br><span class="line"></span><br><span class="line">    return loss, dx</span><br></pre></td></tr></table></figure>



<h1 id="rnn-py"><a href="#rnn-py" class="headerlink" title="rnn_py"></a>rnn_py</h1><p>loss函数：</p>
<p>input_dim:输入的图片特征D</p>
<p>word_to_idx:输入的所有单词表，即V</p>
<p>wordvec_dim:我理解为每个单词的长度D</p>
<p>hidden_dim:RNN循环层隐藏状态h</p>
<p>captions_in:输入的描述单词序列为start开始，end结束，因此这里的输入截止到end之前，数据集本身它是有做标识的，start是开始，end是结束</p>
<p>captions_out:输出的描述单词的序列，不输出start，因此从1开始，</p>
<p>features:图像特征[N,D]</p>
<p>vocab_size:所有单词的数量，即V</p>
<p>captions:真实的说明，即单词构成的序列[N,T]</p>
<p>W_proj:[D,H]</p>
<p>b_proj:[H,]</p>
<p>W_embed:[V,D]用于生成[N,T,D]每张图像的单词序列向量</p>
<p>W_vocab:[H,V]生成对应的所有单词的得分的权值</p>
<p>b_vacab:对于所有单词得分的偏置值。</p>
<p>T只是要选择的单词</p>
<p>RNN训练的核心就是隐藏状态的表示的是图像的特征，然后输入的X是单词序列的特征，因此可以训练。</p>
<p>实现步骤：</p>
<p>1.形成初始图像的隐藏状态  [N,H]  </p>
<p>2.生成单词向量[N,T,D]</p>
<p>3.使用RNN来处理输入的单词向量序列，并生成整个隐藏状态h[N,T,H]</p>
<p>4.使用编写好的函数temporal affine求出score即得分 [N,T,V]</p>
<p>5.这个就用到了最初设定的Mask掩膜矩阵可以忽略NULL单词的损失</p>
<p>这是我完全个人写出来的一个函数~~~，进步了~，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line">class CaptioningRNN(object):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    A CaptioningRNN produces captions from image features using a recurrent</span><br><span class="line">    neural network.</span><br><span class="line"></span><br><span class="line">    The RNN receives input vectors of size D, has a vocab size of V, works on</span><br><span class="line">    sequences of length T, has an RNN hidden dimension of H, uses word vectors</span><br><span class="line">    of dimension W, and operates on minibatches of size N.</span><br><span class="line"></span><br><span class="line">    Note that we don&#x27;t use any regularization for the CaptioningRNN.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, word_to_idx, input_dim=512, wordvec_dim=128,</span><br><span class="line">                 hidden_dim=128, cell_type=&#x27;rnn&#x27;, dtype=np.float32):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Construct a new CaptioningRNN instance.</span><br><span class="line"></span><br><span class="line">        Inputs:</span><br><span class="line">        - word_to_idx: A dictionary giving the vocabulary. It contains V entries,</span><br><span class="line">          and maps each string to a unique integer in the range [0, V).</span><br><span class="line">        - input_dim: Dimension D of input image feature vectors.</span><br><span class="line">        - wordvec_dim: Dimension W of word vectors.</span><br><span class="line">        - hidden_dim: Dimension H for the hidden state of the RNN.</span><br><span class="line">        - cell_type: What type of RNN to use; either &#x27;rnn&#x27; or &#x27;lstm&#x27;.</span><br><span class="line">        - dtype: numpy datatype to use; use float32 for training and float64 for</span><br><span class="line">          numeric gradient checking.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if cell_type not in &#123;&#x27;rnn&#x27;, &#x27;lstm&#x27;&#125;:</span><br><span class="line">            raise ValueError(&#x27;Invalid cell_type &quot;%s&quot;&#x27; % cell_type)</span><br><span class="line"></span><br><span class="line">        self.cell_type = cell_type</span><br><span class="line">        self.dtype = dtype</span><br><span class="line">        self.word_to_idx = word_to_idx</span><br><span class="line">        self.idx_to_word = &#123;i: w for w, i in word_to_idx.items()&#125;</span><br><span class="line">        self.params = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        vocab_size = len(word_to_idx)</span><br><span class="line"></span><br><span class="line">        self._null = word_to_idx[&#x27;&lt;NULL&gt;&#x27;]</span><br><span class="line">        self._start = word_to_idx.get(&#x27;&lt;START&gt;&#x27;, None)</span><br><span class="line">        self._end = word_to_idx.get(&#x27;&lt;END&gt;&#x27;, None)</span><br><span class="line"></span><br><span class="line">        # Initialize word vectors</span><br><span class="line">        self.params[&#x27;W_embed&#x27;] = np.random.randn(vocab_size, wordvec_dim)  #[V,D]</span><br><span class="line">        self.params[&#x27;W_embed&#x27;] /= 100</span><br><span class="line"></span><br><span class="line">        # Initialize CNN -&gt; hidden state projection parameters</span><br><span class="line">        self.params[&#x27;W_proj&#x27;] = np.random.randn(input_dim, hidden_dim)</span><br><span class="line">        self.params[&#x27;W_proj&#x27;] /= np.sqrt(input_dim)</span><br><span class="line">        self.params[&#x27;b_proj&#x27;] = np.zeros(hidden_dim)</span><br><span class="line"></span><br><span class="line">        # Initialize parameters for the RNN</span><br><span class="line">        dim_mul = &#123;&#x27;lstm&#x27;: 4, &#x27;rnn&#x27;: 1&#125;[cell_type]</span><br><span class="line">        self.params[&#x27;Wx&#x27;] = np.random.randn(wordvec_dim, dim_mul * hidden_dim)</span><br><span class="line">        self.params[&#x27;Wx&#x27;] /= np.sqrt(wordvec_dim)</span><br><span class="line">        self.params[&#x27;Wh&#x27;] = np.random.randn(hidden_dim, dim_mul * hidden_dim)</span><br><span class="line">        self.params[&#x27;Wh&#x27;] /= np.sqrt(hidden_dim)</span><br><span class="line">        self.params[&#x27;b&#x27;] = np.zeros(dim_mul * hidden_dim)</span><br><span class="line"></span><br><span class="line">        # Initialize output to vocab weights</span><br><span class="line">        self.params[&#x27;W_vocab&#x27;] = np.random.randn(hidden_dim, vocab_size)</span><br><span class="line">        self.params[&#x27;W_vocab&#x27;] /= np.sqrt(hidden_dim)</span><br><span class="line">        self.params[&#x27;b_vocab&#x27;] = np.zeros(vocab_size)</span><br><span class="line"></span><br><span class="line">        # Cast parameters to correct dtype</span><br><span class="line">        for k, v in self.params.items():</span><br><span class="line">            self.params[k] = v.astype(self.dtype)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def loss(self, features, captions):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Compute training-time loss for the RNN. We input image features and</span><br><span class="line">        ground-truth captions for those images, and use an RNN (or LSTM) to compute</span><br><span class="line">        loss and gradients on all parameters.</span><br><span class="line"></span><br><span class="line">        Inputs:</span><br><span class="line">        - features: Input image features, of shape (N, D)</span><br><span class="line">        - captions: Ground-truth captions; an integer array of shape (N, T) where</span><br><span class="line">          each element is in the range 0 &lt;= y[i, t] &lt; V</span><br><span class="line"></span><br><span class="line">        Returns a tuple of:</span><br><span class="line">        - loss: Scalar loss</span><br><span class="line">        - grads: Dictionary of gradients parallel to self.params</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # Cut captions into two pieces: captions_in has everything but the last word</span><br><span class="line">        # and will be input to the RNN; captions_out has everything but the first</span><br><span class="line">        # word and this is what we will expect the RNN to generate. These are offset</span><br><span class="line">        # by one relative to each other because the RNN should produce word (t+1)</span><br><span class="line">        # after receiving word t. The first element of captions_in will be the START</span><br><span class="line">        # token, and the first element of captions_out will be the first word.</span><br><span class="line">        captions_in = captions[:, :-1]</span><br><span class="line">        captions_out = captions[:, 1:]</span><br><span class="line"></span><br><span class="line">        # You&#x27;ll need this</span><br><span class="line">        mask = (captions_out != self._null)</span><br><span class="line"></span><br><span class="line">        # Weight and bias for the affine transform from image features to initial</span><br><span class="line">        # hidden state</span><br><span class="line">        W_proj, b_proj = self.params[&#x27;W_proj&#x27;], self.params[&#x27;b_proj&#x27;]</span><br><span class="line"></span><br><span class="line">        # Word embedding matrix</span><br><span class="line">        W_embed = self.params[&#x27;W_embed&#x27;]</span><br><span class="line"></span><br><span class="line">        # Input-to-hidden, hidden-to-hidden, and biases for the RNN</span><br><span class="line">        Wx, Wh, b = self.params[&#x27;Wx&#x27;], self.params[&#x27;Wh&#x27;], self.params[&#x27;b&#x27;]</span><br><span class="line"></span><br><span class="line">        # Weight and bias for the hidden-to-vocab transformation.</span><br><span class="line">        W_vocab, b_vocab = self.params[&#x27;W_vocab&#x27;], self.params[&#x27;b_vocab&#x27;]</span><br><span class="line"></span><br><span class="line">        loss, grads = 0.0, &#123;&#125;</span><br><span class="line">        ############################################################################</span><br><span class="line">        # TODO: Implement the forward and backward passes for the CaptioningRNN.   #</span><br><span class="line">        # In the forward pass you will need to do the following:                   #</span><br><span class="line">        # (1) Use an affine transformation to compute the initial hidden state     #</span><br><span class="line">        #     from the image features. This should produce an array of shape (N, H)#</span><br><span class="line">        # (2) Use a word embedding layer to transform the words in captions_in     #</span><br><span class="line">        #     from indices to vectors, giving an array of shape (N, T, W).         #</span><br><span class="line">        # (3) Use either a vanilla RNN or LSTM (depending on self.cell_type) to    #</span><br><span class="line">        #     process the sequence of input word vectors and produce hidden state  #</span><br><span class="line">        #     vectors for all timesteps, producing an array of shape (N, T, H).    #</span><br><span class="line">        # (4) Use a (temporal) affine transformation to compute scores over the    #</span><br><span class="line">        #     vocabulary at every timestep using the hidden states, giving an      #</span><br><span class="line">        #     array of shape (N, T, V).                                            #</span><br><span class="line">        # (5) Use (temporal) softmax to compute loss using captions_out, ignoring  #</span><br><span class="line">        #     the points where the output word is &lt;NULL&gt; using the mask above.     #</span><br><span class="line">        #                                                                          #</span><br><span class="line">        # In the backward pass you will need to compute the gradient of the loss   #</span><br><span class="line">        # with respect to all model parameters. Use the loss and grads variables   #</span><br><span class="line">        # defined above to store loss and gradients; grads[k] should give the      #</span><br><span class="line">        # gradients for self.params[k].                                            #</span><br><span class="line">        ############################################################################</span><br><span class="line">        h0,cache_0=affine_forward(features,W_proj,b_proj)</span><br><span class="line">        #h0=features.dot(W_proj)+b_proj</span><br><span class="line">        x,cache0=word_embedding_forward(captions_in,W_embed)</span><br><span class="line">        h,cache1=rnn_forward(x,h0,Wx,Wh,b)</span><br><span class="line">        score,cache2=temporal_affine_forward(h,W_vocab,b_vocab)</span><br><span class="line">        loss,dscore=temporal_softmax_loss(score,captions_out,mask)</span><br><span class="line">        </span><br><span class="line">        dout,dW_vocab,db_vocab=temporal_affine_backward(dscore,cache2)</span><br><span class="line">        grads[&#x27;W_vocab&#x27;]=dW_vocab</span><br><span class="line">        grads[&#x27;b_vocab&#x27;]=db_vocab</span><br><span class="line">        </span><br><span class="line">        dout,dh0,dWx,dWh,db=rnn_backward(dout,cache1)</span><br><span class="line">       # grads[&#x27;h0&#x27;]=dh0</span><br><span class="line">        grads[&#x27;Wx&#x27;]=dWx</span><br><span class="line">        grads[&#x27;Wh&#x27;]=dWh</span><br><span class="line">        grads[&#x27;b&#x27;]=db</span><br><span class="line">        </span><br><span class="line">        dW_embed=word_embedding_backward(dout,cache0)</span><br><span class="line">        grads[&#x27;W_embed&#x27;]=dW_embed</span><br><span class="line">        </span><br><span class="line">        dout,dW_proj,db_proj=affine_backward(dh0,cache_0)</span><br><span class="line">        grads[&#x27;W_proj&#x27;]=dW_proj</span><br><span class="line">        grads[&#x27;b_proj&#x27;]=db_proj</span><br><span class="line">        </span><br><span class="line">        pass</span><br><span class="line">        ############################################################################</span><br><span class="line">        #                             END OF YOUR CODE                             #</span><br><span class="line">        ############################################################################</span><br><span class="line"></span><br><span class="line">        return loss, grads</span><br></pre></td></tr></table></figure>

<p>sample函数，在训练中，由于是对N个图像T个单词分别进行预测，因此直接使用rnn_forward。但是在测试样本中，需要对一个N张图像一个单词一个单词进行预测，因此需要使用rnn_step_forward,并且在word_embedding_forward中可以仅仅代入一个单词即x[N,i]。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">    def sample(self, features, max_length=30):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Run a test-time forward pass for the model, sampling captions for input</span><br><span class="line">        feature vectors.</span><br><span class="line"></span><br><span class="line">        At each timestep, we embed the current word, pass it and the previous hidden</span><br><span class="line">        state to the RNN to get the next hidden state, use the hidden state to get</span><br><span class="line">        scores for all vocab words, and choose the word with the highest score as</span><br><span class="line">        the next word. The initial hidden state is computed by applying an affine</span><br><span class="line">        transform to the input image features, and the initial word is the &lt;START&gt;</span><br><span class="line">        token.</span><br><span class="line"></span><br><span class="line">        For LSTMs you will also have to keep track of the cell state; in that case</span><br><span class="line">        the initial cell state should be zero.</span><br><span class="line"></span><br><span class="line">        Inputs:</span><br><span class="line">        - features: Array of input image features of shape (N, D).</span><br><span class="line">        - max_length: Maximum length T of generated captions.</span><br><span class="line"></span><br><span class="line">        Returns:</span><br><span class="line">        - captions: Array of shape (N, max_length) giving sampled captions,</span><br><span class="line">          where each element is an integer in the range [0, V). The first element</span><br><span class="line">          of captions should be the first sampled word, not the &lt;START&gt; token.</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        N = features.shape[0]</span><br><span class="line">        captions = self._null * np.ones((N, max_length), dtype=np.int32)</span><br><span class="line"></span><br><span class="line">        # Unpack parameters</span><br><span class="line">        W_proj, b_proj = self.params[&#x27;W_proj&#x27;], self.params[&#x27;b_proj&#x27;]</span><br><span class="line">        W_embed = self.params[&#x27;W_embed&#x27;]</span><br><span class="line">        Wx, Wh, b = self.params[&#x27;Wx&#x27;], self.params[&#x27;Wh&#x27;], self.params[&#x27;b&#x27;]</span><br><span class="line">        W_vocab, b_vocab = self.params[&#x27;W_vocab&#x27;], self.params[&#x27;b_vocab&#x27;]</span><br><span class="line"></span><br><span class="line">        ###########################################################################</span><br><span class="line">        # TODO: Implement test-time sampling for the model. You will need to      #</span><br><span class="line">        # initialize the hidden state of the RNN by applying the learned affine   #</span><br><span class="line">        # transform to the input image features. The first word that you feed to  #</span><br><span class="line">        # the RNN should be the &lt;START&gt; token; its value is stored in the         #</span><br><span class="line">        # variable self._start. At each timestep you will need to do to:          #</span><br><span class="line">        # (1) Embed the previous word using the learned word embeddings           #</span><br><span class="line">        # (2) Make an RNN step using the previous hidden state and the embedded   #</span><br><span class="line">        #     current word to get the next hidden state.                          #</span><br><span class="line">        # (3) Apply the learned affine transformation to the next hidden state to #</span><br><span class="line">        #     get scores for all words in the vocabulary                          #</span><br><span class="line">        # (4) Select the word with the highest score as the next word, writing it #</span><br><span class="line">        #     to the appropriate slot in the captions variable                    #</span><br><span class="line">        #                                                                         #</span><br><span class="line">        # For simplicity, you do not need to stop generating after an &lt;END&gt; token #</span><br><span class="line">        # is sampled, but you can if you want to.                                 #</span><br><span class="line">        #                                                                         #</span><br><span class="line">        # HINT: You will not be able to use the rnn_forward or lstm_forward       #</span><br><span class="line">        # functions; you&#x27;ll need to call rnn_step_forward or lstm_step_forward in #</span><br><span class="line">        # a loop.                                                                 #</span><br><span class="line">        ###########################################################################</span><br><span class="line">#         h,cache0=affine_forward(features,W_proj,b_proj)</span><br><span class="line">#         for layer in range(max_length):</span><br><span class="line">        c = np.zeros(b.shape[0]//4)</span><br><span class="line">        h = features.dot(W_proj) + b_proj  # (1)</span><br><span class="line">        captions[:, 0] = self._start</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        for iter_time in range(1, max_length):</span><br><span class="line">            prev_word = captions[:, iter_time-1]</span><br><span class="line">            captions_in_vec, _ = word_embedding_forward(prev_word, W_embed)  #(2)</span><br><span class="line">            if self.cell_type == &quot;rnn&quot;:</span><br><span class="line">                h, _ = rnn_step_forward(captions_in_vec, h, Wx, Wh, b)  # (3)</span><br><span class="line">            else:</span><br><span class="line">                h, c, _ = lstm_step_forward(captions_in_vec, h, c, Wx, Wh, b)  # (3)</span><br><span class="line">            scores =  np.dot(h, W_vocab) + b_vocab  # (4)</span><br><span class="line">            captions[:, iter_time] = np.argmax(scores, axis=1)</span><br><span class="line"></span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">        </span><br><span class="line">        pass</span><br><span class="line">        ############################################################################</span><br><span class="line">        #                             END OF YOUR CODE                             #</span><br><span class="line">        ############################################################################</span><br><span class="line">        return captions</span><br></pre></td></tr></table></figure>


        </div>
        
<blockquote class="copyright">
    <p><strong>Link to this article : </strong><a class="permalink" href="http://yoursite.com/2020/07/10/CS231n_Assignment3_Image_Captioning_with_RNNs/">http://yoursite.com/2020/07/10/CS231n_Assignment3_Image_Captioning_with_RNNs/</a></p>
    <p><strong>This article is available under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)</a> License</strong></p>
</blockquote>


    </article>
    
    <section id="comments">
        
    </section>


    

</main>


<aside style="" id="sidebar" class="aside aside-fixture">
    <div class="toc-sidebar">
        <nav id="toc" class="article-toc">
            <h3 class="toc-title">Catalogue</h3>
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Image-Captioning-with-RNNs"><span class="toc-number">1.</span> <span class="toc-text">Image Captioning with RNNs</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Microsoft-COCO"><span class="toc-number">1.0.1.</span> <span class="toc-text">Microsoft COCO</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Recurrent-Neural-Networks-%E6%AD%A3%E6%96%87%E6%AE%B5%E5%BC%80%E5%A7%8B-RNN"><span class="toc-number">1.0.2.</span> <span class="toc-text">Recurrent Neural Networks 正文段开始 RNN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Vanilla-RNN-step-forward"><span class="toc-number">1.0.3.</span> <span class="toc-text">Vanilla RNN: step forward</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Vanilla-RNN-step-backward"><span class="toc-number">1.0.4.</span> <span class="toc-text">Vanilla RNN: step backward</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Vanilla-RNN-forward"><span class="toc-number">1.0.5.</span> <span class="toc-text">Vanilla RNN: forward</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Vanilla-RNN-backward"><span class="toc-number">1.0.6.</span> <span class="toc-text">Vanilla RNN: backward</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Word-embedding-forward"><span class="toc-number">1.0.7.</span> <span class="toc-text">Word embedding: forward</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Word-embedding-backward"><span class="toc-number">1.0.8.</span> <span class="toc-text">Word embedding: backward</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Temporal-Affine-layer"><span class="toc-number">1.0.9.</span> <span class="toc-text">Temporal Affine layer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Temporal-Softmax-loss"><span class="toc-number">1.0.10.</span> <span class="toc-text">Temporal Softmax loss</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RNN-for-image-captioning"><span class="toc-number">1.0.11.</span> <span class="toc-text">RNN for image captioning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Overfit-small-data"><span class="toc-number">1.0.12.</span> <span class="toc-text">Overfit small data</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Test-time-sampling"><span class="toc-number">1.0.13.</span> <span class="toc-text">Test-time sampling</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#rnn-layers-py"><span class="toc-number">2.</span> <span class="toc-text">rnn_layers.py</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#rnn-py"><span class="toc-number">3.</span> <span class="toc-text">rnn_py</span></a></li></ol>
        </nav>
    </div>
</aside>





        </section>
        <footer class="hidden lg:block fixed bottom-0 left-0 sm:w-1/12 lg:w-1/6 bg-gray-100 z-40">
    
    <div class="footer-social-links">
        
            <a target="_blank" rel="noopener" href="https://github.com/fengkx">
                <i class="iconfont icon-github"></i>
            </a>
        
            <a target="_blank" rel="noopener" href="https://t.me/fengkx">
                <i class="iconfont icon-telegram"></i>
            </a>
        
            <a target="_blank" rel="noopener" href="https://twitter.com/example">
                <i class="iconfont icon-twitter"></i>
            </a>
        
            <a href="/atom.xml">
                <i class="iconfont icon-rss"></i>
            </a>
        
    </div>
    
    
</footer>

        <div id="mask" class="hidden mask fixed inset-0 bg-gray-900 opacity-75 z-40"></div>
        <div id="search-view-container" class="hidden shadow-xl"></div>
        
<script src="/js/dom-event.min.js"></script>



<script src="/js/local-search.min.js"></script>



    <script src="//cdn.jsdelivr.net/npm/lightgallery.js@1.1.3/dist/js/lightgallery.min.js"></script>
    
<script src="/js/light-gallery.min.js"></script>






    </body>
</html>
